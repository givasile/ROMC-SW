\input{latex_files/graphs/romc_graph}

The overview of our implementation is illustrated in
Figure~\ref{fig:romc_overview}. Following \proglang{Python}'s naming
principles, the methods starting with an underscore (green rectangles)
represent internal (private) functions, whereas the rest (blue
ellipses) are the methods exposed as the public API. In
Figure~\ref{fig:romc_overview}, it can be easily observed that the
implementation follows Algorithm~\ref{alg:romc_algorithm}. The
training part includes all the steps until the computation of the
proposal regions i.e.~sampling the nuisance variables, defining the
optimisation problems, solving them, constructing the regions and
fitting local surrogate models. The inference part comprises of
evaluating the unnormalised posterior (and the normalised when is
possible), sampling and computing an expectation. We also provide some
utilities for inspecting the training process, such as plotting the
histogram of the final distances or visualising the constructed
bounding boxes. Finally, in the evaluation part, we provide two
methods for evaluating the inference; (a) computing the Effective
Sample Size (ESS) of the samples and (b) measuring the divergence
between the approximate posterior the ground-truth, if the latter is
available.\footnote{Normally, the ground-truth posterior is not
  available; However, this functionality is useful in cases where the
  posterior can be computed numerically or with an alternative method
  (i.e.\ ABC Rejection Sampling), and we would like to measure the
  discrepancy between the two approximations.}

\subsubsection*{Parallelising ROMC method}

ROMC has the significant advantage of being fully parallelisable. We
exploit this fact by implementing a parallel version of all the major
components of the method; (a) solving the optimisation problems, (b)
constructing bounding box regions, (c) sampling and (d) evaluating the
posterior. We parallelise these processes using the built-in
\proglang{Python} package \pkg{multiprocessing}. The specific package
enables concurrency, using subprocesses instead of threads, for
side-stepping the Global Interpreter (GIL). For activating the
parallel version of the algorithm, the user simpy has to pass the
argument \code{parallelize=True} when instantiating \code{ROMC}.

\begin{Code}
---------------------------------- python ----------------------------------
>>> elfi.ROMC(<output_node>, parallelize=True)
----------------------------------------------------------------------------
\end{Code}
  
\subsubsection*{Simple one-dimensional example}

For illustrating the functionalities we will use the following running
example introduced by \citet{Ikonomov2019},

\begin{gather} \label{eq:1D_example}
  p(\theta) = \mathcal{U}(\theta;-2.5,2.5)\\ \label{eq:1D_example_eq_2}
  p(y|\theta) = \left\{
    \begin{array}{ll} \theta^4 + u & \mbox{if } \theta \in [-0.5, 0.5]
\\ |\theta| - c + u & \mbox{otherwise}
    \end{array} \right.\\ 
  u \sim \mathcal{N}(0,1)
\end{gather}

\noindent

The prior is a uniform distribution in the range \([-2.5, 2.5]\) and
the likelihood is defined at~\ref{eq:1D_example_eq_2}. The constant
\(c\) is \(0.5 - 0.5^4\) ensures the continuity of the pdf. There is
only one observation \(y_0 = 0\). The inference in this particular
example can be performed quite easily without using a likelihood-free
inference approach. We can exploit this fact for validating the
accuracy of our implementation.

In the following code snippet, we code the model at \pkg{ELFI}.

\begin{Code}
------------------------------ python snippet ------------------------------
  import elfi
  import scipy.stats as ss
  import numpy as np

  def simulator(t1, batch_size=1,random_state=None):
    c = 0.5 - 0.5**4
    if t1 < -0.5:
        y = ss.norm(loc=-t1-c, scale=1).rvs(random_state=random_state)
    elif t1 <= 0.5:
        y = ss.norm(loc=t1**4, scale=1).rvs(random_state=random_state)
    else:
        y = ss.norm(loc=t1-c, scale=1).rvs(random_state=random_state)
    return y

  # observation
  y = 0

  # Elfi graph
  t1 = elfi.Prior('uniform', -2.5, 5)
  sim = elfi.Simulator(simulator, t1, observed=y)
  d = elfi.Distance('euclidean', sim)

  # Initialise the ROMC inference method
  bounds = [(-2.5, 2.5)] # limits of the prior
  parallelize = True # activate parallel execution
  romc = elfi.ROMC(d, bounds=bounds, parallelize=parallelize)
----------------------------------------------------------------------------
\end{Code}
