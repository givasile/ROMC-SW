\citet{Ikonomov2019} showed that considering infinitesimally small ellipses can lead
to highly overconfident posteriors. We refer the reader to their paper
for the technical details and conditions for this issue to
occur. Intuitively, it happens because the weights in OMC are only
computed from information at $\thetab_i^*$. And using only local
information can be misleading. For example if the curvature of
$||\Phi(\data)-\Phi(\simulator(\thetab, \vb_i))||_2$ at $\thetab_i^*$
is nearly flat, the curvature alone may wrongly indicate that
$\accregioni$ is much larger than it actually is. We implement in our
software package the robust generalisation of OMC
by \citet{Ikonomov2019} that resolves this issue.

ROMC approximates the acceptance regions $\accregioni$ and defines
local proposal distributions $q_i(\thetab)$ on them from which the
posterior samples $\thetab_{ij} \sim q_i$ are generated. The samples
are assigned (importance) weights $w_{ij}$ that compensate for using
the proposal distributions $q_i(\thetab)$ and not the prior
$p(\thetab)$,
\begin{equation}
  w_{ij} = \frac{\indicator{\accregioni}(\thetab_{ij}) p(\thetab_{ij})}{q(\thetab_{ij})}.
  \label{eq:sampling}
\end{equation}
Given the weighted samples, any expectation
$\Ex_{p(\thetab|\data)}[h(\thetab)]$ of some function $h(\thetab)$, can be approximated as
\begin{equation} \label{eq:expectation}
  \Ex_{p(\thetab|\data)}[h(\thetab)] \approx \frac{\sum_{ij} w_{ij} h(\thetab_{ij})}{\sum_{ij} w_{ij}}
\end{equation}
\citet{Ikonomov2019} considered uniform distributions as proposal
distributions so that the main work is to approximate the acceptance
regions $\accregioni$ and to represent them such that uniform sampling is
easy. The approximation of the acceptance regions contains two compulsory
and one optional step: (1) solving the optimisation problems as in OMC, (2)
constructing bounding boxes around $\accregioni$ and optionally, (3)
refining the approximation via a probabilistic surrogate model of the distance.
\subsubsection*{Solving the deterministic optimisation problems}
For each set of nuisance variables $\vb_i, i = \{1,2,\ldots,n_1 \}$, we
search for a point $\thetab^*_i$ such that
$d(\simulator(\thetab^*_i,\vb_i), \data) \le \epsilon$. For notational
convenience, we denote the distance $d(\simulator(\thetab,\vb_i), \data)$ by
$d_i(\thetab)$.  Obtaining $\theta_i^*$ involves solving the following
optimisation problem:
\begin{subequations}
\begin{alignat}{2}      
  &\!\min_{\thetab}        && d_i(\thetab) \label{eq:optProb}\\
  &\text{subject to} & \quad& d_i(\thetab) \leq \epsilon
\end{alignat}
\end{subequations}
%
The optimisation problem can be treated as unconstrained, accepting
the optimal point $\thetab_i^* = \text{argmin}_{\thetab} d_i(\thetab)$
only if $d_i(\thetab_i^*) \le \epsilon$. If $d_i(\thetab)$ is
differentiable any gradient-based optimizer can be used
for~\ref{eq:optProb}. The gradients $\nabla_{\thetab} d_i(\thetab)$
can be either provided in closed form or approximated by finite
differences. In case $d_i$ is not differentiable, Bayesian
Optimisation~\cite{Shahriari2016} provides an alternative choice. In
this scenario, apart from obtaining an optimal $\thetab_i^* $, a
surrogate model $\hat{d}_i(\thetab)$ of the distance function
$d_i(\thetab)$ is also automatically obtained; $\hat{d}_i$ can then
substitute the actual distance function in downstream steps of the
algorithms, which can lead to computational gains if running the
simulator and hence evaluating the distance function $d_i(\thetab)$ is
computationally expensive.

\subsubsection*{Estimating the acceptance regions}
The acceptance region $\accregioni$ is approximated by a bounding box
$\accregionihat$ around it. Ideally, we want the bounding box to be as
tight as possible to $\mathcal{S}_i$, to ensure high acceptance rate
in the importance sampling, and big enough for not discarding valid
parts of $\mathcal{S}_i$. \TODO{did remove the issue of disconnected
sets; which needed to be handled by multiple restarts with the same
seed. Is this something that the code would support? It's expensive
because we don't know when we need it! I think it's an open research
question, not related to this software paper, so I omitted it.} The
bounding boxes are built in two steps. First, we define their axes
$\mathbf{v}_d$ based on the (estimated) curvature of the distance
$\thetab_i^*$, second, we determine the size of the box via a
one-dimensional line-search method along each axix, see
Algorithm~\ref{alg:region_construction} for the details. After the
bounding boxes construction, a uniform distribution $q_i$ is defined
on each bounding box, and is used as the proposal region for
importance sampling.

\subsubsection*{Refining the estimate via a local surrogate model (optional)}
When computing the weight $w_{ij}$ in \eqref{eq:sampling}, we need to
check whether the samples $\thetab_{ij} \sim q_i$ lie inside the
acceptance region $\accregioni$. This can be considered to be a
safety-mechanism that corrects for any inaccuracies in the
construction of $\accregionihat$ above. However, this check involves
evaluting the distance function $d_i(\thetab_{ij})$ and hence running
the simulator $\simulator(\thetab_{ij}, \vb_i)$, which can be
expensive if the model is complex.

\citet{Ikonomov2019} thus proposed to construct a surrogate model $\hat{d}_i(\thetab)$
of the distance function $d_i(\thetab)$ valid in $\accregionihat$ and
that is is cheap to evaluate. They used a simple quadratic model
whilst other regression models are, in principle, possible too. The
advantage of using a quadratic model is that it has ellipsoidal
isocontours, which thus naturally allowed \citet{Ikonomov2019} to
replace the bounding box approximation of $\accregioni$ with a
tigher-fitting ellipsoidal approximation.\footnote{The difference to
the infinitesimal ellipsoidal model in OMC is the estimation procedure: OMC uses
information at $\thetab_i^*$ whilst, here, information in
$\accregionihat$ is used, which results in a more stable fit.}

The training data for fitting the quadratic model is obtained by
sampling $\thetab \sim q_i$ and evaluating the corresponding distances
$d_i(\thetab)$. The generation of the training data adds an extra
computational cost, but leads to a significant speed-up when
evaluating the weights $w_{ij}$. Moreover, the extra cost is largely
eliminated if Bayesian Optimization with a Gaussian processe (GP)
surrogate model was used to obtain $\thetab_i^*$ in the first place
(see above). In this case, we can use the GP model of the distance
function instead of $d_i(\thetab)$ to generate the training data. This
essentially replaces the global GP model with a simpler local
quadratic model which is typically more robust.



